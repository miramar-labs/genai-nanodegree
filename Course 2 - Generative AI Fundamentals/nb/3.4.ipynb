{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Use a foundation model to build a spam email classifier\n",
    "\n",
    "A foundation model serves as a fundamental building block for potentially endless applications. One application we will explore in this exercise is the development of a spam email classifier using only the prompt. By leveraging the capabilities of a foundation model, this project aims to accurately identify and filter out unwanted and potentially harmful emails, enhancing user experience and security.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Identify and gather relevant data\n",
    "2. Build and evaluate the spam email classifier\n",
    "3. Build an improved classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identify and gather relevant data\n",
    "\n",
    "To train and test the spam email classifier, you will need a dataset of emails that are labeled as spam or not spam. It is important to identify and gather a suitable dataset that represents a wide range of spam and non-spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=0, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label=0, sms=Ok lar... Joking wif u oni...\n",
      "\n",
      "label=1, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find a spam dataset at https://huggingface.co/datasets and load it using the datasets library\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sms_spam\", split=[\"train\"])[0]\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label = entry[\"label\"]\n",
    "    print(f\"label={label}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Those labels could be easier to read. Let's create some functions to convert numerical ids to labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label=NOT SPAM, sms=Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "label=NOT SPAM, sms=Ok lar... Joking wif u oni...\n",
      "\n",
      "label=SPAM, sms=Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convenient dictionaries to convert between labels and ids\n",
    "id2label = {0: \"NOT SPAM\", 1: \"SPAM\"}\n",
    "label2id = {\"NOT SPAM\": 0, \"SPAM\": 1}\n",
    "\n",
    "for entry in dataset.select(range(3)):\n",
    "    sms = entry[\"sms\"]\n",
    "    label_id = entry[\"label\"]\n",
    "    print(f\"label={id2label[label_id]}, sms={sms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Build and evaluate the spam email classifier\n",
    "\n",
    "Using the foundation model and the prepared dataset, you can create a spam email classifier.\n",
    "\n",
    "Let's write a prompt that will ask the model to classify 15 message as either \"spam\" or \"not spam\". For easier parsing, we can ask the LLM to respond in JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (label=NOT SPAM) -> Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "1 (label=NOT SPAM) -> Ok lar... Joking wif u oni...\n",
      "\n",
      "2 (label=SPAM) -> Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's start with this helper function that will help us format sms messages\n",
    "# for the LLM.\n",
    "def get_sms_messages_string(dataset, item_numbers, include_labels=False):\n",
    "    sms_messages_string = \"\"\n",
    "    for item_number, entry in zip(item_numbers, dataset.select(item_numbers)):\n",
    "        sms = entry[\"sms\"]\n",
    "        label_id = entry[\"label\"]\n",
    "\n",
    "        if include_labels:\n",
    "            sms_messages_string += (\n",
    "                f\"{item_number} (label={id2label[label_id]}) -> {sms}\\n\"\n",
    "            )\n",
    "        else:\n",
    "            sms_messages_string += f\"{item_number} -> {sms}\\n\"\n",
    "\n",
    "    return sms_messages_string\n",
    "\n",
    "\n",
    "print(get_sms_messages_string(dataset, range(3), include_labels=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a bit of code that will produce your prompt. Your prompt should include a few SMS message to be labelled as well as instructions for the LLM.\n",
    "\n",
    "Some LLMs will also format the output for you as JSON if you ask them, e.g. \"Respond in JSON format.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7 -> As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "8 -> WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "9 -> Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      "10 -> I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "\n",
      "11 -> SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
      "\n",
      "12 -> URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
      "\n",
      "13 -> I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
      "\n",
      "14 -> I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "\n",
      "\n",
      "---\n",
      "Classify the messages above as SPAM or NOT SPAM. Respond in JSON format.\n",
      "Use the following format: {\"0\": \"NOT SPAM\", \"1\": \"SPAM\"}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with your code\n",
    "\n",
    "# Get a few messages and format them as a string\n",
    "sms_messages_string = get_sms_messages_string(dataset, range(7, 15))\n",
    "\n",
    "# Construct a query to send to the LLM including the sms messages.\n",
    "# Ask it to respond in JSON format.\n",
    "query = f\"\"\"\n",
    "{sms_messages_string}\n",
    "---\n",
    "Classify the messages above as SPAM or NOT SPAM. Respond in JSON format.\n",
    "Use the following format: {{\"0\": \"NOT SPAM\", \"1\": \"SPAM\"}}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your LLMs response\n",
    "\n",
    "response = {\n",
    "  \"7\": \"NOT SPAM\",\n",
    "  \"8\": \"SPAM\",\n",
    "  \"9\": \"SPAM\",\n",
    "  \"10\": \"NOT SPAM\",\n",
    "  \"11\": \"SPAM\",\n",
    "  \"12\": \"SPAM\",\n",
    "  \"13\": \"NOT SPAM\",\n",
    "  \"14\": \"NOT SPAM\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Estimate the accuracy of your classifier by comparing your responses to the labels in the dataset\n",
    "\n",
    "\n",
    "def get_accuracy(response, dataset, original_indices):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for entry_number, prediction in response.items():\n",
    "        if int(entry_number) not in original_indices:\n",
    "            continue\n",
    "\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        # If the prediction from the LLM matches the label in the dataset\n",
    "        # we increment the number of correct predictions.\n",
    "        # (Since LLMs do not always produce the same output, we use the\n",
    "        # lower case version of the strings for comparison)\n",
    "        if prediction.lower() == label.lower():\n",
    "            correct += 1\n",
    "\n",
    "        # increment the total number of predictions\n",
    "        total += 1\n",
    "\n",
    "    try:\n",
    "        accuracy = correct / total\n",
    "    except ZeroDivisionError:\n",
    "        print(\"No matching results found!\")\n",
    "        return\n",
    "\n",
    "    return round(accuracy, 2)\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7, 15))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not bad! (Assuming you used an LLM capable of handling this task)\n",
    "\n",
    "Surely it won't be correct for every example we throw at it, but it's a great start, especially for not giving it any examples or training data.\n",
    "\n",
    "We can see that the model is able to distinguish between spam and non-spam messages with a high degree of accuracy. This is a great example of how a foundation model can be used to build a spam email classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Build an improved classifier?\n",
    "\n",
    "If you provide the LLM with some examples for how to complete a task, it will sometimes improve its performance. Let's try that out here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "54 (label=SPAM) -> SMS. ac Sptv: The New Jersey Devils and the Detroit Red Wings play Ice Hockey. Correct or Incorrect? End? Reply END SPTV\n",
      "\n",
      "55 (label=NOT SPAM) -> Do you know what Mallika Sherawat did yesterday? Find out now @  &lt;URL&gt;\n",
      "\n",
      "56 (label=SPAM) -> Congrats! 1 year special cinema pass for 2 is yours. call 09061209465 now! C Suprman V, Matrix3, StarWars3, etc all 4 FREE! bx420-ip4-5we. 150pm. Dont miss out! \n",
      "\n",
      "57 (label=NOT SPAM) -> Sorry, I'll call later in meeting.\n",
      "\n",
      "58 (label=NOT SPAM) -> Tell where you reached\n",
      "\n",
      "59 (label=NOT SPAM) -> Yes..gauti and sehwag out of odi series.\n",
      "\n",
      "\n",
      "7 -> As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "8 -> WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "9 -> Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      "10 -> I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\n",
      "\n",
      "11 -> SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info\n",
      "\n",
      "12 -> URGENT! You have won a 1 week FREE membership in our £100,000 Prize Jackpot! Txt the word: CLAIM to No: 81010 T&C www.dbuk.net LCCLTD POBOX 4403LDNW1A7RW18\n",
      "\n",
      "13 -> I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\n",
      "\n",
      "14 -> I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "\n",
      "\n",
      "---\n",
      "Classify the messages above as SPAM or NOT SPAM. Respond in JSON format.\n",
      "Use the following format: {\"0\": \"NOT SPAM\", \"1\": \"SPAM\"}.\n",
      "Some examples have been labeled for you.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace <MASK> with your code that constructs a query to send to the LLM\n",
    "\n",
    "# Get a few labelled messages and format them as a string\n",
    "sms_messages_string_w_labels = get_sms_messages_string(\n",
    "    dataset, range(54, 60), include_labels=True\n",
    ")\n",
    "\n",
    "# Get a few unlabelled messages and format them as a string\n",
    "sms_messages_string_no_labels = get_sms_messages_string(dataset, range(7, 15))\n",
    "\n",
    "\n",
    "# Construct a query to send to the LLM including the labelled messages\n",
    "# as well as the unlabelled messages. Ask it to respond in JSON format\n",
    "query = f\"\"\"\n",
    "{sms_messages_string_w_labels}\n",
    "{sms_messages_string_no_labels}\n",
    "---\n",
    "Classify the messages above as SPAM or NOT SPAM. Respond in JSON format.\n",
    "Use the following format: {{\"0\": \"NOT SPAM\", \"1\": \"SPAM\"}}.\n",
    "Some examples have been labeled for you.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-1.82.0-py3-none-any.whl (720 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting typing-extensions<5,>=4.11\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /home/student/.local/lib/python3.10/site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: sniffio in /home/student/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/student/.local/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.5/352.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /home/student/.local/lib/python3.10/site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: tqdm>4 in /home/student/.local/lib/python3.10/site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/student/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/student/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: httpcore==1.* in /home/student/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: certifi in /home/student/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/student/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/student/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/student/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Installing collected packages: typing-extensions, jiter, distro, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.10.0\n",
      "    Uninstalling typing_extensions-4.10.0:\n",
      "      Successfully uninstalled typing_extensions-4.10.0\n",
      "\u001b[33m  WARNING: The script distro is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: The script openai is installed in '/home/student/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed distro-1.9.0 jiter-0.10.0 openai-1.82.0 typing-extensions-4.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Paste your key here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "inp = f\"\"\"\n",
    "{sms_messages_string_w_labels}\n",
    "{sms_messages_string_no_labels}\n",
    "\"\"\"\n",
    "\n",
    "instruct = \"\"\"\n",
    "Classify the messages above as SPAM or NOT SPAM. Respond in JSON format.\n",
    "Use the following format: {\"0\": \"NOT SPAM\", \"1\": \"SPAM\"}.\n",
    "Some examples have been labeled for you.\n",
    "\"\"\"\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    instructions=instruct,\n",
    "    input=inp,\n",
    ")\n",
    "\n",
    "print(response.output_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paste in your response from the LLM below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace <MASK> with your LLMs response\n",
    "\n",
    "response = {\n",
    "  \"7\": \"NOT SPAM\",\n",
    "  \"8\": \"SPAM\",\n",
    "  \"9\": \"SPAM\",\n",
    "  \"10\": \"NOT SPAM\",\n",
    "  \"11\": \"SPAM\",\n",
    "  \"12\": \"SPAM\",\n",
    "  \"13\": \"NOT SPAM\",\n",
    "  \"14\": \"NOT SPAM\",\n",
    "  \"54\": \"SPAM\",\n",
    "  \"55\": \"NOT SPAM\",\n",
    "  \"56\": \"SPAM\",\n",
    "  \"57\": \"NOT SPAM\",\n",
    "  \"58\": \"NOT SPAM\",\n",
    "  \"59\": \"NOT SPAM\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the accuracy now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# What's the accuracy?\n",
    "\n",
    "print(f\"Accuracy: {get_accuracy(response, dataset, range(7,15)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any misclassified items, let's view them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the messages that were misclassified, if you have any\n",
    "\n",
    "\n",
    "def print_misclassified_messages(response, dataset):\n",
    "    for entry_number, prediction in response.items():\n",
    "        label_id = dataset[int(entry_number)][\"label\"]\n",
    "        label = id2label[label_id]\n",
    "\n",
    "        if prediction.lower() != label.lower():\n",
    "            sms = dataset[int(entry_number)][\"sms\"]\n",
    "            print(\"---\")\n",
    "            print(f\"Message: {sms}\")\n",
    "            print(f\"Label: {label}\")\n",
    "            print(f\"Prediction: {prediction}\")\n",
    "\n",
    "\n",
    "print_misclassified_messages(response, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting (if there were any mistakes). What do you think is going on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

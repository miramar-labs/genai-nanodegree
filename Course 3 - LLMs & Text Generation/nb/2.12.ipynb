{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74a6c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Creating Embeddings\n",
    "**Classic methods for vectorization** (such as bag-of-words, one-hot encoding, and TF-IDF) can **lack contextual relationships**.\n",
    "\n",
    "**Embeddings** can encode context by vectorizing text/tokens into **representational vectors**.\n",
    "\n",
    "### Properties of Embeddings\n",
    "\n",
    "![](./img/img8.png)\n",
    "\n",
    "![](./img/img9.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9deb02",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "[StatQuest: Word Embedding](https://www.youtube.com/watch?v=Qf06XDYXCXI)\n",
    "\n",
    "[StatQuest: Cosine Similarity](https://www.youtube.com/watch?v=e9U0QAFbfLI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afd38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

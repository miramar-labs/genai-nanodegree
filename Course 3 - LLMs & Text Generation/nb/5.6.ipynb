{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74a6c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Sometimes, a simple requests.get isn't enough. This may be due to a block from robots.txt or something more sophisticated like anti-scraping or anti-DDoS techniques. In other cases, the page may be rendering a lot of dynamic content that we cannot easily access with BeautifulSoup. Regardless, our ability to collect the text we're looking for will be encumbered, and we'll have to turn to more advanced methods.\n",
    "\n",
    "### Scrapy and Selenium\n",
    "Two Python libraries that can prove to be incredibly useful for web scraping when requests is insufficient are [selenium](https://www.selenium.dev/) and [scrapy](https://scrapy.org/). Other options, like automated scraping platforms, do exist, but these can get quite expensive and may lack the customization one might want.\n",
    "\n",
    "#### Selenium\n",
    "Selenium is a browser automation framework. When we use Selenium, we are actually browsing the site using a real browser. Note that this browser will often be \"headless\", so we won't actually render anything on the screen.\n",
    "\n",
    "    from selenium import webdriver\n",
    "    from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "\n",
    "    driver = webdriver.Chrome(options=options, executable_path='/path/to/chromedriver')\n",
    "    driver.get(\"https://www.udacity.com/\")\n",
    "    page_source = driver.page_source\n",
    "    with open(\"udacity_home.html\", \"w\") as f:\n",
    "        f.write(page_source)\n",
    "    driver.quit()\n",
    "\n",
    "The above code is a simple Selenium example.\n",
    "\n",
    "First, we import the webdriver and the Options object.\n",
    "\n",
    "Then, we create an Options object, and specify options.headless = True so that Selenium does not actually open a browser window for us. This option is incredibly important if we're scraping many pages and even more so if we're on a resource-constrained system!\n",
    "\n",
    "We can use the options.add_argument() to pass additional arguments to Selenium, like a window size that makes the system seem more real.\n",
    "\n",
    "We initialize the Chrome webdriver with the following code:\n",
    "\n",
    "    driver = webdriver.Chrome(options=options, executable_path='/path/to/chromedriver')\n",
    "\n",
    "This will create the actual object that navigates to the page for us, and we need only specify the options we're interested in, plus the path to the Chrome driver on our machine.\n",
    "\n",
    "Using driver.get(), we send a GET request for the page in question, just like we do with requests. However, in this case, the site will see a \"normal\" web browser originating the request and is less likely to drop it. Once we've made a successful GET request, the source of the page -- where all the text we're interested in is located -- is within the driver.page_source object.\n",
    "\n",
    "We can then use that the same way we do the .text or .content attribute of a response from requests.\n",
    "\n",
    "Finally, it's good practice to run driver.quit() so we don't run into scoping issues.\n",
    "\n",
    "#### Scrapy\n",
    "Scrapy is a framework for building web spiders that can be run either locally or in the [Zyte cloud](https://www.zyte.com/scrapy-cloud/). As a scraping framework as opposed to a headless browser, Scrapy is highly performant and scalable. When you have to scrape large amounts of data from the internet, Scrapy is therefore a fantastic option. We recommend following the [Scrapy tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html) for learning how to use Scrapy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9deb02",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afd38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

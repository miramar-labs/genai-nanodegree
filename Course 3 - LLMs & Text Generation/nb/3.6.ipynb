{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74a6c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "![](./img/img28.png)\n",
    "\n",
    "![](./img/img29.png)\n",
    "\n",
    "![](./img/img30.png)\n",
    "\n",
    "![](./img/img31.png)\n",
    "\n",
    "### \"Attention Is All You Need\"?\n",
    "If self-attention is so powerful, can it replace RNNs altogether? Vaswani et al. (2017) argues that it can, with the right solutions in place to address its limitations.\n",
    "\n",
    "- Problem: lack of input order\n",
    "  - As previously described with ELMo, context is important for understanding the meaning of words.\n",
    "  - Self-attention doesn't understand this by default, so we add positional encodings as part of the input embeddings.\n",
    "- Problem: no nonlinearity between repeated self-attention layers\n",
    "  - The reason that we typically use an activation function like ReLU in a neural network layer, rather than just a linear output, is to enable to model to capture more complexity. Linear outputs can be reduced to a simple y=mx+b style formula.\n",
    "  - Self-attention layers don't have this nonlinearity by default, so we add a feed-forward network for each processed token afterward.\n",
    "- Problem: \"cheating\" when predicting a sequence\n",
    "  - The goal of a deep learning model is to be able to predict some unknown information given some known information. If all of the information is known, the model can't learn the relationships properly.\n",
    "  - By default, self-attention can look at all of the data, including the \"future\" that it is trying to predict. To prevent this, we mask attention on future words during decoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9deb02",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "[A Decomposable Attention Model for Natural Language Inference (Parikh et al., 2016)](https://arxiv.org/abs/1606.01933v2)\n",
    "\n",
    "[Attention Is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762)\n",
    "\n",
    "[Understanding Parameter Sharing in Transformers (Lin et al., 2023)](https://arxiv.org/abs/2306.09380)\n",
    "\n",
    "[Falcon model documentation on Hugging Face](https://huggingface.co/docs/transformers/main/model_doc/falcon)\n",
    "\n",
    "[LLaMA 2 model documentation on Hugging Face](https://huggingface.co/docs/transformers/model_doc/llama2)\n",
    "\n",
    "[HiCLIP: Contrastive Language-Image Pretraining with Hierarchy-aware Attention (Geng et al., 2023)](https://arxiv.org/abs/2303.02995)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afd38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

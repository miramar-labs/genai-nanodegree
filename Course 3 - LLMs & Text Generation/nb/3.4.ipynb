{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74a6c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Attention scores** are mathematical definitions of attention\n",
    "\n",
    "**Attention mechanisms** describe how the mathematical definitions are applied to different sets of Q,K,V\n",
    "\n",
    "The query, key, value terminology used in describing attention has its roots in the database field.\n",
    "\n",
    "![](./img/img18.png)\n",
    "\n",
    "![](./img/img19.png)\n",
    "\n",
    "![](./img/img20.png)\n",
    "\n",
    "### Attention Score Calculations\n",
    "There are three main ways we think about calculating attention: multiplicative, additive, and general.\n",
    "\n",
    "![](./img/img21.png)\n",
    "\n",
    "![](./img/img22.png)\n",
    "\n",
    "![](./img/img23.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9deb02",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "[3blue1brown: Attention in Transformers](https://www.youtube.com/watch?v=eMlx5fFNoYc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afd38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74a6c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Three types:\n",
    "\n",
    "- Encoder-Only (eg BERT)\n",
    "- Encoder-Decoder (eg original T5)\n",
    "- Decoder-Only (eg GPT)\n",
    "\n",
    "![](./img/img32.png)\n",
    "\n",
    "### Positional Encodings\n",
    "Because Transformers process tokens in parallel (unlike RNNs/LSTMs/GRUs etc)... they have no concept of ordering in the sequence being processed. So we encode 'sequence position' by adding a unique position vector to each token embedding vector:\n",
    "\n",
    "    embedding(\"The\") + positional_encoding(0)\n",
    "    embedding(\"cat\") + positional_encoding(1)\n",
    "    embedding(\"sat\") + positional_encoding(2)\n",
    "\n",
    "There are various types of positional encodings:\n",
    "\n",
    "- Absolute\n",
    "  - Sinusoidal \n",
    "  - Learned \n",
    "- Relative\n",
    "  - TransformerXL\n",
    "- Rotary\n",
    "\n",
    "### Residual Connections\n",
    "A residual connection is a type of skipped layer, designed to address the vanishing gradient problem. It originated from the 2015 ResNets paper by He et al. and was originally used for computer vision tasks.\n",
    "\n",
    "### Layer Normalization\n",
    "Layer normalization is the process of subtracting the mean and dividing by the standard deviation of the inputs for each sample. This stabilizes and speeds up the model training.\n",
    "\n",
    "Similar to the scaled attention score described previously, this step is helpful because of how it impacts the gradients that neural networks use for backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9deb02",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Devlin et al., 2018)](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "[Improving Language Understanding by Generative Pre-Training (Radford et al., 2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
    "\n",
    "[Learning Positional Embeddings for Coordinate-MLPs (Ramasinghe & Lucey, 2021)](https://arxiv.org/abs/2112.11577)\n",
    "\n",
    "[CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings (Likhomanenko et al., 2021)](https://arxiv.org/abs/2106.03143)\n",
    "\n",
    "[RoFormer: Enhanced Transformer with Rotary Position Embedding (Su et al., 2021)](https://arxiv.org/abs/2104.09864)\n",
    "\n",
    "[Deep Residual Learning for Image Recognition (He et al., 2015)](https://arxiv.org/abs/1512.03385)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afd38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

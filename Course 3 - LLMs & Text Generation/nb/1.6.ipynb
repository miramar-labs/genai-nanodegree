{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74a6c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- Instruction Fine-Tuning can be achieved from:\n",
    "  - Providing in-domain supervised dataset (often hard to construct)\n",
    "  - Using existing in-domain fine-tuned LLM together with synthetic dataset\n",
    "  \n",
    "    LLMs can be used for the generation of training data along multiple dimensions, including:\n",
    "\n",
    "    - Generation of responses from pre-existing queries.\n",
    "        - Enabling instruction fine-tuning dataset pairs: \n",
    "\n",
    "                {\"prompt\": <existing_instruction>, \"completion\": <LLM_generated_response>}\n",
    "\n",
    "        - This is probably the most straightforward usage of LLMs for synthetic dataset generation.\n",
    "        - Ensure LLM's license supports such usage.\n",
    "    - Generation of instructions from pre-existing documents.\n",
    "        - Enabling instruction fine-tuning dataset pairs: \n",
    "            \n",
    "                {\"prompt\": <LLM_generated_instruction>, \"completion\": <existing_document_chunk>}\n",
    "\n",
    "        - This method, known as back-translation from the development of translation systems for low-resource languages, has been given this modern spin in [Self-Alignment with Instruction Backtranslation](https://arxiv.org/abs/2308.06259)\n",
    "    - Generation of preference data from existing prompt/response LLM pairs:\n",
    "        - For example, the comparison of:\n",
    "\n",
    "                {{\"prompt\": <prompt_0>, \"completion\": <completion_a>}, \"pref\": LLM_generated_preference_1}} \n",
    "        \n",
    "        vs.\n",
    "        \n",
    "                {{\"prompt\": <prompt_0>, \"completion\": <completion_a>}, \"pref\": LLM_generated_preference_-1}}\n",
    "\n",
    "        - This can be used for Reinforcement Learning from Human Feedback (despite the feedback being non-human in this case), as explored more in [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9deb02",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afd38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

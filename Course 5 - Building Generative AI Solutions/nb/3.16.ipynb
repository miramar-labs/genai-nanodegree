{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d74a6c5",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Retrieval Augmented Generation (RAG), is a technique that enhances the capabilities of large language models (LLMs). RAG can integrate a company's data, like a knowledge base, with LLMs. This allows applications to leverage both the power of LLMs and the specific information contained in the company's own data.\n",
    "\n",
    "![](./img/img7.png)\n",
    "\n",
    "![](./img/img8.png)\n",
    "\n",
    "### How It Works\n",
    "- The process begins with a user query, which is used to search a vector database. Vector databases are used to store data. These databases are essential for adding additional, semantically relevant information to the LLM\n",
    "- The system then retrieves documents that are semantically closest to the query.\n",
    "- The retrieved documents are passed along with the original query to the LLM. This provides the LLM with extra context and up-to-date information, resulting in a more informed and accurate response.\n",
    "- Document transformers are used to prepare data by breaking it into smaller chunks. This is beneficial for indexing large documents and achieving a more precise match between the user's query and the document content.\n",
    "- Text Embedding Models convert document chunks into embeddings that capture the semantic meaning of the data.\n",
    "- Vector Storage is where the embeddings are stored, ready for retrieval.\n",
    "- Retrievers fetch the semantically relevant chunks for the LLM to process.\n",
    "The RAG system allows for efficient use of LLMs by not overwhelming them with data and ensures precise and accurate output.\n",
    "\n",
    "### Code from Video\n",
    "\n",
    "    from langchain.indexes import VectorstoreIndexCreator\n",
    "    from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "    loader = CSVLoader(file_path='./tv-reviews.csv')\n",
    "\n",
    "    index = VectorstoreIndexCreator().from_loaders([loader])\n",
    "\n",
    "    query = \"Based on the reviews in the context, tell me what people liked about the picture quality\"\n",
    "    index.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9deb02",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "[]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91afd38",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
